{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Part_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jKrGxfgKeVSD"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,4)\n",
        "print(x)\n",
        "print(x.size())\n",
        "#reshape the tensor x\n",
        "y = x.view(5,-1)\n",
        "y.add_(x)\n",
        "print(y.size())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAQcLdqneXsu",
        "outputId": "588671f8-ed93-4fbe-879d-ed2b9ae53d00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0298, 0.7673, 0.7811, 0.2769],\n",
            "        [0.4413, 0.2531, 0.9828, 0.5017],\n",
            "        [0.9386, 0.5231, 0.8596, 0.8485],\n",
            "        [0.2645, 0.3166, 0.5818, 0.0460],\n",
            "        [0.6828, 0.8027, 0.3338, 0.1513]])\n",
            "torch.Size([5, 4])\n",
            "torch.Size([5, 4])\n",
            "tensor([[0.0596, 1.5345, 1.5622, 0.5539],\n",
            "        [0.8825, 0.5062, 1.9656, 1.0034],\n",
            "        [1.8772, 1.0463, 1.7192, 1.6970],\n",
            "        [0.5290, 0.6331, 1.1636, 0.0921],\n",
            "        [1.3656, 1.6054, 0.6676, 0.3026]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "#forward pass\n",
        "y_prediction = w * x\n",
        "loss = (y_prediction - y)**2\n",
        "##Backward passs\n",
        "loss.backward()\n",
        "print(w.grad) ## weight value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XtrQNQWocU4",
        "outputId": "c4855b4b-7e24-4d1b-d854-58d485d3fa43"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manually Gradient**"
      ],
      "metadata": {
        "id": "Pi2N5ZQjm5DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "grDCYkgoYy0_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,9,2,4], dtype = np.float32)\n",
        "y = np.array([4,1,7,3], dtype = np.float32)\n",
        "w = 0.0\n"
      ],
      "metadata": {
        "id": "g1St08mWZINu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forward pass\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "#loss\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean() \n",
        "\n",
        "\n",
        "#Gradient\n",
        "def gradient(y, y_pred, loss):\n",
        "  return np.dot(2*x, (y-y_pred)).mean()\n",
        "\n",
        "print(f'Predict before traing: f(5)=  {forward(5):.3f}')\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iter = 10\n",
        "\n",
        "for epoch in range(n_iter):\n",
        "  y_pred = forward(x)\n",
        "\n",
        "  l = loss(y,y_pred)\n",
        "\n",
        "  dw = gradient(x,y,y_pred)\n",
        "\n",
        "\n",
        "  #update weight\n",
        "  w -= learning_rate * dw\n",
        "  if epoch %  1 == 0:\n",
        "    print(f'epoch {epoch}: w = {w:.03f}, loss = {l: 0.8f}')\n",
        "\n",
        "print(f'Predict after traing: f(5)= {forward(5):.3f}')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6ZieSpeaN5x",
        "outputId": "39d9565f-b1cf-4b0a-fb99-f1e98570451e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict before traing: f(5)=  -252.000\n",
            "epoch 0: w = -51.660, loss =  65775.63281250\n",
            "epoch 1: w = -52.920, loss =  69079.38281250\n",
            "epoch 2: w = -54.180, loss =  72464.10937500\n",
            "epoch 3: w = -55.440, loss =  75929.80468750\n",
            "epoch 4: w = -56.700, loss =  79476.46875000\n",
            "epoch 5: w = -57.960, loss =  83104.09375000\n",
            "epoch 6: w = -59.220, loss =  86812.68750000\n",
            "epoch 7: w = -60.480, loss =  90602.25000000\n",
            "epoch 8: w = -61.740, loss =  94472.78125000\n",
            "epoch 9: w = -63.000, loss =  98424.29687500\n",
            "Predict after traing: f(5)= -315.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Automate gradient\n",
        "\n",
        "x = torch.tensor([1,9,2,4], dtype = torch.float32)\n",
        "y = torch.tensor([4,1,7,3], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, requires_grad = True) #We have to update weight value so use \"requires_grad = True\"\n",
        "\n",
        "#forward pass\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "#loss\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean() \n",
        "\n",
        "\n",
        "print(f'Predict before traing: f(5)=  {forward(5):.3f}')\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iter = 50\n",
        "\n",
        "for epoch in range(n_iter):\n",
        "  y_pred = forward(x)\n",
        "\n",
        "  l = loss(y,y_pred)\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "\n",
        "  #update weight\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad ##No gradient function\n",
        "\n",
        "  w.grad.zero_() ##Gradient value is again zero \n",
        "  if epoch %  1 == 0:\n",
        "    print(f'epoch {epoch}: w = {w:.03f}, loss = {l: 0.8f}')\n",
        "\n",
        "print(f'Predict after traing: f(5)= {forward(5):.3f}')  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5uOgJHLeyJ0",
        "outputId": "81bd7bf2-ebcc-43c5-d279-433144c14a49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict before traing: f(5)=  0.000\n",
            "epoch 0: w = 0.195, loss =  18.75000000\n",
            "epoch 1: w = 0.291, loss =  15.91713715\n",
            "epoch 2: w = 0.337, loss =  15.23696709\n",
            "epoch 3: w = 0.360, loss =  15.07365894\n",
            "epoch 4: w = 0.372, loss =  15.03444767\n",
            "epoch 5: w = 0.377, loss =  15.02503300\n",
            "epoch 6: w = 0.380, loss =  15.02277279\n",
            "epoch 7: w = 0.381, loss =  15.02223015\n",
            "epoch 8: w = 0.382, loss =  15.02210045\n",
            "epoch 9: w = 0.382, loss =  15.02206802\n",
            "epoch 10: w = 0.382, loss =  15.02206135\n",
            "epoch 11: w = 0.382, loss =  15.02205849\n",
            "epoch 12: w = 0.382, loss =  15.02205944\n",
            "epoch 13: w = 0.382, loss =  15.02205849\n",
            "epoch 14: w = 0.382, loss =  15.02205849\n",
            "epoch 15: w = 0.382, loss =  15.02205944\n",
            "epoch 16: w = 0.382, loss =  15.02205849\n",
            "epoch 17: w = 0.382, loss =  15.02205944\n",
            "epoch 18: w = 0.382, loss =  15.02205849\n",
            "epoch 19: w = 0.382, loss =  15.02205944\n",
            "epoch 20: w = 0.382, loss =  15.02205753\n",
            "epoch 21: w = 0.382, loss =  15.02205944\n",
            "epoch 22: w = 0.382, loss =  15.02205944\n",
            "epoch 23: w = 0.382, loss =  15.02205849\n",
            "epoch 24: w = 0.382, loss =  15.02205849\n",
            "epoch 25: w = 0.382, loss =  15.02205849\n",
            "epoch 26: w = 0.382, loss =  15.02205849\n",
            "epoch 27: w = 0.382, loss =  15.02205849\n",
            "epoch 28: w = 0.382, loss =  15.02205849\n",
            "epoch 29: w = 0.382, loss =  15.02205849\n",
            "epoch 30: w = 0.382, loss =  15.02205849\n",
            "epoch 31: w = 0.382, loss =  15.02205849\n",
            "epoch 32: w = 0.382, loss =  15.02205849\n",
            "epoch 33: w = 0.382, loss =  15.02205849\n",
            "epoch 34: w = 0.382, loss =  15.02205849\n",
            "epoch 35: w = 0.382, loss =  15.02205849\n",
            "epoch 36: w = 0.382, loss =  15.02205849\n",
            "epoch 37: w = 0.382, loss =  15.02205849\n",
            "epoch 38: w = 0.382, loss =  15.02205849\n",
            "epoch 39: w = 0.382, loss =  15.02205849\n",
            "epoch 40: w = 0.382, loss =  15.02205849\n",
            "epoch 41: w = 0.382, loss =  15.02205849\n",
            "epoch 42: w = 0.382, loss =  15.02205849\n",
            "epoch 43: w = 0.382, loss =  15.02205849\n",
            "epoch 44: w = 0.382, loss =  15.02205849\n",
            "epoch 45: w = 0.382, loss =  15.02205849\n",
            "epoch 46: w = 0.382, loss =  15.02205849\n",
            "epoch 47: w = 0.382, loss =  15.02205849\n",
            "epoch 48: w = 0.382, loss =  15.02205849\n",
            "epoch 49: w = 0.382, loss =  15.02205849\n",
            "Predict after traing: f(5)= 1.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TU0Y43S8k5wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}